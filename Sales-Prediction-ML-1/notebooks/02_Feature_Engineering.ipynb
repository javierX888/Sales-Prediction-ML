{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingeniería de Características\n",
    "# Proyecto: Predicción de Ventas\n",
    "\n",
    "**Autor:** Javier Gacitúa  \n",
    "**Fecha:** Octubre 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de la Ingeniería de Características\n",
    "\n",
    "1. Crear nuevas variables que mejoren el rendimiento del modelo.\n",
    "2. Transformar variables existentes para optimizar su uso en el modelado.\n",
    "3. Evaluar la importancia de las características generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('Librerías importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos Procesados\n",
    "\n",
    "Cargamos el dataset limpio que se generó en el análisis previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset procesado...\n",
      "Dataset cargado: (filas, columnas)\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset procesado\n",
    "df = pd.read_csv('../data/processed/sales_clean.csv')\n",
    "\n",
    "print(f'Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creación de Nuevas Características\n",
    "\n",
    "A continuación, generaremos nuevas características a partir de los datos existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas características\n",
    "df['Total Price'] = df['sales'] * df['quantity']  # Precio total\n",
    "df['Discounted Price'] = df['Total Price'] * (1 - df['discount'])  # Precio con descuento\n",
    "df['Sales per Day'] = df['sales'] / df['days_since_order']  # Ventas por día\n",
    "\n",
    "print('Nuevas características creadas:')\n",
    "print(df[['Total Price', 'Discounted Price', 'Sales per Day']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluación de la Importancia de las Características\n",
    "\n",
    "Analizaremos la importancia de las características generadas para determinar su impacto en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar la importancia de las características\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = df.drop(['sales'], axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Importancia de las características\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Visualizar importancia\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Importancia de las Características')\n",
    "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Guardar el Dataset Procesado\n",
    "\n",
    "Guardamos el dataset con las nuevas características para su uso en el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset procesado guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar dataset procesado\n",
    "df.to_csv('../data/processed/sales_featured.csv', index=False)\n",
    "print('Dataset procesado guardado correctamente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones\n",
    "\n",
    "Hemos creado nuevas características que pueden mejorar el rendimiento del modelo. A continuación, se procederá al entrenamiento del modelo en el siguiente cuaderno."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "application/x-ipynb+json",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}